{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf33f319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blanca/anaconda3/envs/py38/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#model: https://github.com/kristpapadopoulos/seriesnet/blob/master/seriesnet.py\n",
    "#causalconv1: https://github.com/pytorch/pytorch/issues/1333\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from math import sqrt\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.trunc_normal_(m.weight, 0.0, 0.05)\n",
    "\n",
    "class CausalConv1d(torch.nn.Conv1d):\n",
    "    def __init__(self,nb_filter,filter_length,dilation,device):\n",
    "        self.__padding = ((filter_length - 1) * dilation)\n",
    "        \n",
    "        #(batch, in_channels, in_length) \n",
    "        super(CausalConv1d, self).__init__(7,out_channels = nb_filter,kernel_size=filter_length,\n",
    "            stride=1,padding=self.__padding,dilation=dilation,groups=1,bias=False,device=device)\n",
    "\n",
    "    def forward(self, x_input,cond): \n",
    "        \"\"\" x_input = [32,7,6], cond=[32,2]\"\"\"\n",
    "        conv1d_out = super(CausalConv1d, self).forward(x_input)\n",
    "        conv1d_out = conv1d_out[:, :, :-self.__padding] if self.__padding != 0 else conv1d_out\n",
    "        return conv1d_out\n",
    "\n",
    "class DC_CNN_Block(torch.nn.Module):\n",
    "    def __init__(self,nb_filter, filter_length, dilation, num_features):\n",
    "        super(DC_CNN_Block, self).__init__()\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.nb_filter = nb_filter\n",
    "        self.filter_length= filter_length\n",
    "        self.dilation = dilation\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.causal = CausalConv1d(self.nb_filter,self.filter_length,self.dilation,device=device)\n",
    "        self.skip_out = nn.Conv1d(6,out_channels=self.num_features,kernel_size=1,stride=6,bias=False,device=device)\n",
    "        self.network_in = nn.Conv1d(6,out_channels=self.num_features,kernel_size=1,stride=6,bias=False,device=device)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.causal.apply(weight_init)\n",
    "        self.skip_out.apply(weight_init)\n",
    "        self.network_in.apply(weight_init)\n",
    "\n",
    "    def forward(self, x_input,cond):\n",
    "        dev = x_input.device\n",
    "\n",
    "        residual = x_input #[32,6,7]\n",
    "        x = x_input.permute(0,2,1).to(dev) #[32,7,6]\n",
    "\n",
    "        #[32,7,6] => [32,32,6]\n",
    "        layer_out = self.causal(x,cond).to(dev)\n",
    "        layer_out = layer_out.permute(0,2,1).to(dev) #[32, 6, 32]\n",
    "        layer_out = F.selu(layer_out) #[32, 6, 32]\n",
    "\n",
    "        #[32, 6, 32] => [32, 7, 6]\n",
    "        skip_out = self.skip_out(layer_out)\n",
    "        skip_out = skip_out.permute(0,2,1).to(dev) #[32, 6, 7]\n",
    "\n",
    "        #[32, 6, 32] => [32, 7, 6]\n",
    "        network_in = self.network_in(layer_out)\n",
    "        network_in = network_in.permute(0,2,1).to(dev) #[32, 6, 7]\n",
    "\n",
    "        network_out = residual + network_in\n",
    "        return network_out, skip_out\n",
    "\n",
    "\n",
    "\n",
    "class CausalModel(pl.LightningModule):\n",
    "    def __init__(self, w_decay,dropout,alpha,gamma,input_seq_length,output_seq_length,\n",
    "                 num_features,lr,num_conditions, path,feature_list,\n",
    "                 net,in_channels,out_channels,kernel_size,stride,dilation,groups,bias):\n",
    "\n",
    "        super(CausalModel,self).__init__()\n",
    "        self.w_decay = w_decay\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.input_seq_length = input_seq_length\n",
    "        self.output_seq_length = output_seq_length\n",
    "        self.num_features = num_features\n",
    "        self.lr = lr\n",
    "        self.num_conditions = num_conditions\n",
    "        self.path = path\n",
    "        self.feature_list = feature_list\n",
    "        self.net = net\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.block_1 = DC_CNN_Block(nb_filter=32, filter_length=2, dilation=1, num_features=self.num_features)\n",
    "        self.block_2 = DC_CNN_Block(nb_filter=32, filter_length=2, dilation=2, num_features=self.num_features)\n",
    "        self.block_3 = DC_CNN_Block(nb_filter=32, filter_length=2, dilation=4, num_features=self.num_features)\n",
    "        self.block_4 = DC_CNN_Block(nb_filter=32, filter_length=2, dilation=8, num_features=self.num_features)\n",
    "        self.block_5 = DC_CNN_Block(nb_filter=32, filter_length=2, dilation=16, num_features=self.num_features)\n",
    "        self.block_6 = DC_CNN_Block(nb_filter=32, filter_length=2, dilation=32, num_features=self.num_features)\n",
    "        self.block_7 = DC_CNN_Block(nb_filter=32, filter_length=2, dilation=64, num_features=self.num_features)\n",
    "        self.l21 = nn.Conv1d(self.num_features,out_channels=self.num_features,kernel_size=1,stride=1,bias=False)\n",
    "\n",
    "        # Initialize weights \n",
    "        self.block_1.apply(weight_init)\n",
    "        self.block_2.apply(weight_init)\n",
    "        self.block_3.apply(weight_init)\n",
    "        self.block_4.apply(weight_init)\n",
    "        self.block_5.apply(weight_init)\n",
    "        self.block_6.apply(weight_init)\n",
    "        self.block_7.apply(weight_init)\n",
    "        self.l21.apply(weight_init)\n",
    "\n",
    "    def forward(self,x_input,cond): \n",
    "        \"\"\"\n",
    "        input sequence: [batch_size, input_seq_length,num_features]\n",
    "        condition: [batch_size,num_conditions]\n",
    "        \"\"\"\n",
    "        dev = x_input.device #[32,6,7]\n",
    "\n",
    "        l1a, l1b = self.block_1(x_input,cond)\n",
    "        l2a, l2b = self.block_2(l1a,cond)\n",
    "        l3a, l3b = self.block_3(l2a,cond)\n",
    "        l4a, l4b = self.block_4(l3a,cond)\n",
    "        l5a, l5b = self.block_5(l4a,cond)\n",
    "        l6a, l6b = self.block_6(l5a,cond)\n",
    "        l6b = nn.Dropout(0.8)(l6b)\n",
    "        l7a, l7b = self.block_7(l6a,cond)\n",
    "        l7b = nn.Dropout(0.8)(l7b)\n",
    "        l8 = l1b + l2b + l3b + l4b + l5b + l6b + l7b\n",
    "        l9 = F.relu(l8)\n",
    "\n",
    "        l9 = l9.permute(0,2,1).to(dev)\n",
    "        l21 = self.l21(l9)\n",
    "        l21 = l21.permute(0,2,1).to(dev)\n",
    "\n",
    "        return l21\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        target_in, target_out,condition, mask = batch\n",
    "        condition = condition[:,:self.num_conditions] #settings to number of conditions\n",
    "        target_in = torch.tensor(target_in, dtype=torch.float32).to(target_in.device)#[32, 6, 7]\n",
    "        target_out = torch.tensor(target_out, dtype=torch.float32).to(target_out.device)#[32, 6, 7]        \n",
    "        \n",
    "        y_pred = self(target_in,condition)#[32, 6, 7]\n",
    "        synth_mask = y_pred\n",
    "        real_mask = target_out\n",
    "    \n",
    "        rmse = rmse_loss(synth_mask,real_mask)\n",
    "        self.log(\"loss_train\", rmse,on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\":rmse,\"past\":target_in,\"ytrue\":target_out,\"ypred\":y_pred,\"conditions\":condition, \"mask\":mask}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        target_in, target_out,condition, mask = batch\n",
    "        condition = condition[:,:self.num_conditions] #settings to number of conditions\n",
    "        target_in = torch.tensor(target_in, dtype=torch.float32).to(target_in.device)\n",
    "        target_out = torch.tensor(target_out, dtype=torch.float32).to(target_out.device)\n",
    "        \n",
    "        y_pred = self(target_in,condition)    \n",
    "        synth_mask = y_pred\n",
    "        real_mask = target_out\n",
    "\n",
    "        rmse = rmse_loss(synth_mask,real_mask)\n",
    "        self.log(\"loss_val\",rmse)\n",
    "        return {\"loss\":rmse,\"past\":target_in,\"ytrue\":target_out,\"ypred\":y_pred,\"conditions\":condition, \"mask\":mask}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        #weight_decay sustituye a: kernel_regularizer=l2(l2_layer_reg))\n",
    "        optimizer = torch.optim.Adam(self.parameters(),lr=0.00075,betas=(0.9, 0.999),weight_decay=0.0)        \n",
    "        return {\"optimizer\": optimizer,\"monitor\": \"loss\",}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
