{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7489768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blanca/anaconda3/envs/py38/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#model: https://github.com/kristpapadopoulos/seriesnet/blob/master/seriesnet.py\n",
    "#causalconv1: https://github.com/pytorch/pytorch/issues/1333\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from math import sqrt\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.trunc_normal_(m.weight, 0.0, 0.05)\n",
    "\n",
    "class CausalConv1d(torch.nn.Conv1d):\n",
    "    def __init__(self,num_conditions,num_features,in_channels,out_channels,kernel_size,dilation,device):\n",
    "        self.__padding = ((kernel_size - 1) * dilation)\n",
    "        \n",
    "        #(batch, in_channels, in_length) \n",
    "        super(CausalConv1d, self).__init__(in_channels = num_features,out_channels = 32,\n",
    "            kernel_size=2,stride=1,padding=self.__padding,dilation=dilation,groups=1,bias=False,device=device)\n",
    "\n",
    "    def forward(self, x_input,cond): \n",
    "        \"\"\" x_input = [32,7,6], cond=[32,2]\"\"\"\n",
    "        conv1d_out = super(CausalConv1d, self).forward(x_input)\n",
    "        conv1d_out = conv1d_out[:, :, :-self.__padding] if self.__padding != 0 else conv1d_out\n",
    "        return conv1d_out\n",
    "\n",
    "class DC_CNN_Block(torch.nn.Module):\n",
    "    def __init__(self,num_conditions,num_features,in_channels,out_channels,kernel_size,dilation):\n",
    "        super(DC_CNN_Block, self).__init__()\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.causal = CausalConv1d(num_conditions,num_features,in_channels, out_channels,kernel_size,dilation,device=device)\n",
    "        self.in_channels= in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_features = num_features\n",
    "        self.causal.apply(weight_init)\n",
    "\n",
    "    def forward(self, x_input,cond):\n",
    "        dev = x_input.device\n",
    "\n",
    "        residual = x_input #[32,6,7]\n",
    "\n",
    "        #[32,6,7] => [32,7,6]\n",
    "        x = x_input.permute(0,2,1).to(dev)\n",
    "\n",
    "        #[32,7,6] => [32,32,6]\n",
    "        layer_out = self.causal(x,cond).to(dev)\n",
    "\n",
    "        #[32,32,6] => [32, 6, 32]\n",
    "        layer_out = layer_out.permute(0,2,1).to(dev) \n",
    "        \n",
    "        #[32, 6, 32] => [32, 6, 32]\n",
    "        layer_out = F.selu(layer_out)\n",
    "\n",
    "        #[32, 7, 6] => [32, 7, 6]\n",
    "        skip_out = nn.Conv1d(in_channels=layer_out.shape[1],out_channels=self.out_channels,kernel_size=1,stride=5,bias=False).to(dev)(layer_out)\n",
    "\n",
    "        #[32, 7, 6] => [32, 7, 6]\n",
    "        network_in = nn.Conv1d(in_channels=layer_out.shape[1],out_channels=self.out_channels,kernel_size=1,stride=5,bias=False).to(dev)(layer_out)\n",
    "\n",
    "        #[32,6,7] + [32,6,7] => [32,6,7]\n",
    "        network_out = residual + network_in\n",
    "        return network_out, skip_out\n",
    "\n",
    "class CausalModel(pl.LightningModule):\n",
    "    def __init__(self, w_decay,dropout,alpha,gamma,input_seq_length,output_seq_length,\n",
    "                 num_features,lr,num_conditions, path,feature_list,\n",
    "                 net,in_channels,out_channels,kernel_size,stride,dilation,groups,bias):\n",
    "\n",
    "        super(CausalModel,self).__init__()\n",
    "        self.w_decay = w_decay\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.input_seq_length = input_seq_length\n",
    "        self.output_seq_length = output_seq_length\n",
    "        self.num_features = num_features\n",
    "        self.lr = lr\n",
    "        self.num_conditions = num_conditions\n",
    "        self.path = path\n",
    "        self.feature_list = feature_list\n",
    "        self.net = net\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.block = DC_CNN_Block(num_conditions=self.num_conditions,num_features=self.num_features,\n",
    "                                  in_channels=self.input_seq_length, out_channels=self.output_seq_length,kernel_size=2,dilation=1)\n",
    "        \n",
    "        self.block.apply(weight_init)# Initialize weights \n",
    "\n",
    "    def forward(self,x_input,cond): \n",
    "        \"\"\"\n",
    "        input sequence: [batch_size, input_seq_length,num_features]\n",
    "        condition: [batch_size,num_conditions]\n",
    "\n",
    "        \"\"\"\n",
    "        dev = x_input.device #[32,6,7]\n",
    "\n",
    "        l1a, l1b = DC_CNN_Block(num_conditions=self.num_conditions,num_features=self.num_features,in_channels=self.input_seq_length, \n",
    "                                out_channels=self.output_seq_length,kernel_size=2,dilation=1)(x_input,cond)\n",
    "        l2a, l2b = DC_CNN_Block(num_conditions=self.num_conditions,num_features=self.num_features,in_channels=self.input_seq_length, \n",
    "                                out_channels=self.output_seq_length,kernel_size=2,dilation=2)(l1a,cond)\n",
    "        l3a, l3b = DC_CNN_Block(num_conditions=self.num_conditions,num_features=self.num_features,in_channels=self.input_seq_length, \n",
    "                                out_channels=self.output_seq_length,kernel_size=2,dilation=4)(l2a,cond)\n",
    "        l4a, l4b = DC_CNN_Block(num_conditions=self.num_conditions,num_features=self.num_features,in_channels=self.input_seq_length, \n",
    "                                out_channels=self.output_seq_length,kernel_size=2,dilation=8)(l3a,cond)\n",
    "        l5a, l5b = DC_CNN_Block(num_conditions=self.num_conditions,num_features=self.num_features,in_channels=self.input_seq_length, \n",
    "                                out_channels=self.output_seq_length,kernel_size=2,dilation=16)(l4a,cond)\n",
    "        l6a, l6b = DC_CNN_Block(num_conditions=self.num_conditions,num_features=self.num_features,in_channels=self.input_seq_length, \n",
    "                                out_channels=self.output_seq_length,kernel_size=2,dilation=32)(l5a,cond)\n",
    "\n",
    "        l6b = nn.Dropout(0.8)(l6b) #dropout used to limit influence of earlier data\n",
    "\n",
    "        l7a, l7b = DC_CNN_Block(num_conditions=self.num_conditions,num_features=self.num_features,in_channels=self.input_seq_length, \n",
    "                                out_channels=self.output_seq_length,kernel_size=2,dilation=64)(l6a,cond)\n",
    "\n",
    "        l7b = nn.Dropout(0.8)(l7b) #dropout used to limit influence of earlier data\n",
    "\n",
    "        l8 = l1b + l2b + l3b + l4b + l5b + l6b + l7b\n",
    "\n",
    "        l9 = F.relu(l8)\n",
    "\n",
    "        kernel_size = 7 if self.input_seq_length ==9 else 1\n",
    "        l21 = nn.Conv1d(in_channels=l9.shape[1],out_channels=self.output_seq_length,kernel_size=1,bias=False).to(dev)(l9)\n",
    "\n",
    "        return l21\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        target_in, target_out,condition, mask = batch\n",
    "        condition = condition[:,:self.num_conditions] #settings to number of conditions\n",
    "        target_in = torch.tensor(target_in, dtype=torch.float32).to(target_in.device)#[32, 6, 7]\n",
    "        target_out = torch.tensor(target_out, dtype=torch.float32).to(target_out.device)#[32, 6, 7]        \n",
    "        \n",
    "        y_pred = self(target_in,condition)#[32, 6, 7]\n",
    "        synth_mask = y_pred\n",
    "        real_mask = target_out\n",
    "\n",
    "        rmse = rmse_loss(synth_mask,real_mask)\n",
    "\n",
    "        self.log(\"loss_train\", rmse,on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\"loss\":rmse,\"past\":target_in,\"ytrue\":target_out,\"ypred\":y_pred,\"conditions\":condition, \"mask\":mask}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        target_in, target_out,condition, mask = batch\n",
    "        condition = condition[:,:self.num_conditions] #settings to number of conditions\n",
    "        target_in = torch.tensor(target_in, dtype=torch.float32).to(target_in.device)#[32, 24, 8]\n",
    "        target_out = torch.tensor(target_out, dtype=torch.float32).to(target_out.device)#[32, 24, 8]        \n",
    "        \n",
    "        y_pred = self(target_in,condition)#[32, 24, 8]    \n",
    "        \n",
    "        synth_mask = y_pred\n",
    "        real_mask = target_out\n",
    "\n",
    "        rmse = rmse_loss(synth_mask,real_mask)\n",
    "        self.log(\"loss_val\",rmse)\n",
    "        return {\"loss\":rmse,\"past\":target_in,\"ytrue\":target_out,\"ypred\":y_pred,\"conditions\":condition, \"mask\":mask}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        #weight_decay sustituye a: kernel_regularizer=l2(l2_layer_reg))\n",
    "        optimizer = torch.optim.Adam(self.parameters(),lr=0.00075,betas=(0.9, 0.999),weight_decay=0.0)        \n",
    "        return {\"optimizer\": optimizer,\"monitor\": \"loss\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196e4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
